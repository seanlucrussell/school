{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic TODO:\n",
    " - Get some audio samples\n",
    " - Figure out how we are gonna read them in\n",
    " - Figure out if we are gonna do fourier analysis or recurrent nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrument Classification Using Nerual Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sean Russell*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online radio services such as Pandora and Spotify try to tailor radio stations to their users. For instance, someone who likes listening to the Beatles will be more likely to listen to other classic rock. However, most of these services do things the old fashioned way: with the blood, sweat and tears of human helpers. Before a song is added to the database of songs to be played, a person must go through the song and add tags to it, such as heavy bass, up-tempo, or electronic. Then the service algorithmically decides what songs to play based upon these tags.\n",
    "\n",
    "This project is really just a starting point into looking at automating the entire process. Having people tag songs by hand is a time consuming process, and is fairly repetitive. This sort of process that requires of human pattern recognition abilities seems like the perfect application for machine learning. So, this document looks at the most basic of the basics: classifying instruments.\n",
    "\n",
    "The goal is to classify an audio file as containing one of five instruments: saxaphone, piano, violin, trumpet, or guitar. Using signal processing techniques to preprocess data and machine learning to create a classifier, a model was made that outperforms random guessing, and in some cases did quite well. Also, in the conclusion, I have a whole bunch of ideas for further expansion and refinement in future works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import soundfile as sf\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from numpy.fft import rfft,rfftfreq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = {'trumpet':0,'violin':1,'guitar':2,'piano':3,'saxaphone':4,\n",
    "           0:'trumpet',1:'violin',2:'guitar',3:'piano',4:'saxaphone',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SplitSamples(samples, widthOfSlice = 2000):\n",
    "    return np.reshape(samples[:len(samples)-len(samples)%widthOfSlice],(-1,widthOfSlice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6,7,8,9])\n",
    "SplitSamples(a,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DeleteSamplesLowAmplitude(samples):\n",
    "    threshold = np.mean(samples) * np.std(samples)\n",
    "    return np.delete(samples,np.where(np.mean(samples,axis=1) < threshold),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FourierTransform(samples):\n",
    "    return np.abs(rfft(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FileToData(filename):\n",
    "    samples,samplerate = sf.read(filename)\n",
    "    samples = SplitSamples(samples)\n",
    "    samples = DeleteSamplesLowAmplitude(samples)\n",
    "    samples = FourierTransform(samples)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GenerateData():\n",
    "    trumpetTrain,trumpetTest = GenerateDataFromLabel('trumpet')\n",
    "    violinTrain,violinTest = GenerateDataFromLabel('violin')\n",
    "    guitarTrain,guitarTest = GenerateDataFromLabel('guitar')\n",
    "    pianoTrain,pianoTest = GenerateDataFromLabel('piano')\n",
    "    saxaphoneTrain,saxaphoneTest = GenerateDataFromLabel('saxaphone')\n",
    "    train = np.vstack((trumpetTrain,violinTrain,guitarTrain,pianoTrain,saxaphoneTrain))\n",
    "    test = np.vstack((trumpetTest,violinTest,guitarTest,pianoTest,saxaphoneTest))\n",
    "    traindata = train[:,1:]\n",
    "    testdata = test[:,1:]\n",
    "    traintargets = train[:,0].astype(int)\n",
    "    testtargets = test[:,0].astype(int)\n",
    "    return traindata,traintargets,testdata,testtargets\n",
    "\n",
    "def GenerateDataFromLabel(label):\n",
    "    train = []\n",
    "    test = []\n",
    "    for file in os.listdir('samples/' + label):\n",
    "        if(file.endswith('.wav')):\n",
    "            if(random.choice([True,True,False])):\n",
    "               train += FileToData('samples/' + label + '/' + file).tolist()\n",
    "            else:\n",
    "               test += FileToData('samples/' + label + '/' + file).tolist()\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    train = np.insert(train,0,classes[label],axis=1)\n",
    "    test = np.insert(test,0,classes[label],axis=1)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateModel():\n",
    "    print('Generating data...')\n",
    "    trainingData,trainingTargets,testingData,testingTargets = GenerateData()\n",
    "    print('Finished generating data. Training model...')\n",
    "    classifier = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(200,50))\n",
    "    classifier.fit(trainingData,trainingTargets)\n",
    "    print('Finished training model. Gathering statistics...')\n",
    "    predicted = classifier.predict(testingData)\n",
    "    totalNumberCorrect = np.sum(predicted == testingTargets)\n",
    "    print('total % correct on testing data:',totalNumberCorrect / len(testingTargets))\n",
    "    predictedVsTargets = np.vstack((predicted,testingTargets)).T\n",
    "    for c in range(5):\n",
    "        subset = predictedVsTargets[predictedVsTargets[:,0] == c]\n",
    "        print('\\t' + classes[c].upper())\n",
    "        print(classes[c],'% correct:',\n",
    "              \"%.2f\" % (100*len(subset[subset[:,0]==subset[:,1]]) / len(subset)))\n",
    "        print('% guessed piano:',\n",
    "              \"%.2f\" % (100*len(subset[subset[:,1]==classes['piano']])/len(subset)))\n",
    "        print('% guessed violin:',\n",
    "              \"%.2f\" % (100*len(subset[subset[:,1]==classes['violin']])/len(subset)))\n",
    "        print('% guessed trumpet:',\n",
    "              \"%.2f\" % (100*len(subset[subset[:,1]==classes['trumpet']])/len(subset)))\n",
    "        print('% guessed guitar:',\n",
    "              \"%.2f\" % (100*len(subset[subset[:,1]==classes['guitar']])/len(subset)))\n",
    "        print('% guessed saxaphone:',\n",
    "              \"%.2f\" % (100*len(subset[subset[:,1]==classes['saxaphone']])/len(subset)))\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ClassifyAudioFile(classifier,filename):\n",
    "    vectors = FileToData(filename)\n",
    "    if len(vectors) < 1:\n",
    "        return -1\n",
    "    predicted = classifier.predict(vectors)\n",
    "    mostPredicted = np.argmax(np.bincount(predicted))\n",
    "    return classes[mostPredicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Finished generating data. Training model..."
     ]
    }
   ],
   "source": [
    "classifier = CreateModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Violin? violin\n",
      "Guitar? guitar\n",
      "Trumpet? trumpet\n"
     ]
    }
   ],
   "source": [
    "print('Violin?',ClassifyAudioFile(classifier,'samples/violin/a2.wav'))\n",
    "print('Guitar?',ClassifyAudioFile(classifier,'samples/guitar/353492__matteshaus__guitchord1.wav'))\n",
    "print('Trumpet?',ClassifyAudioFile(classifier,'samples/trumpet/357326__mtg__trumpet-b3-bad-richness.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piano? trumpet\n"
     ]
    }
   ],
   "source": [
    "print('Piano?',ClassifyAudioFile(classifier,'samples/piano/39206__jobro__piano-ff-058.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lots of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did one more run using all 3 gigs of my data. This did not do anything to fix the issues with the piano gap, however the accuracies for all of the other instruments are now hovering around 90%. Currently, the data is not balanced between all of the instruments. I have 10 times more violin and saxaphone data than piano data. This leads me to believe that if I were to have a more complete set of piano data, the accuracy might improve dramatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Finished generating data. Training model...\n",
      "Finished training model. Gathering statistics...\n",
      "total % correct on testing data: 0.945274576593\n",
      "\tTRUMPET\n",
      "trumpet % correct: 96.09\n",
      "% guessed piano: 0.25\n",
      "% guessed violin: 2.24\n",
      "% guessed trumpet: 96.09\n",
      "% guessed guitar: 0.30\n",
      "% guessed saxaphone: 1.12\n",
      "\tVIOLIN\n",
      "violin % correct: 97.49\n",
      "% guessed piano: 0.07\n",
      "% guessed violin: 97.49\n",
      "% guessed trumpet: 0.90\n",
      "% guessed guitar: 0.48\n",
      "% guessed saxaphone: 1.06\n",
      "\tGUITAR\n",
      "guitar % correct: 88.99\n",
      "% guessed piano: 6.19\n",
      "% guessed violin: 2.20\n",
      "% guessed trumpet: 1.62\n",
      "% guessed guitar: 88.99\n",
      "% guessed saxaphone: 1.00\n",
      "\tPIANO\n",
      "piano % correct: 19.72\n",
      "% guessed piano: 19.72\n",
      "% guessed violin: 0.66\n",
      "% guessed trumpet: 1.60\n",
      "% guessed guitar: 66.10\n",
      "% guessed saxaphone: 11.92\n",
      "\tSAXAPHONE\n",
      "saxaphone % correct: 91.07\n",
      "% guessed piano: 1.45\n",
      "% guessed violin: 1.55\n",
      "% guessed trumpet: 1.18\n",
      "% guessed guitar: 4.75\n",
      "% guessed saxaphone: 91.07\n"
     ]
    }
   ],
   "source": [
    "classifier = CreateModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the classifier works! More or less. With around 70% accuracy, the neural network was able to distinguish between violin, piano, trumpet, saxaphone, and guitar. Preprocessing really helped speed things up and improve the accuracy of the model at least for this problem. However, there is still much that can be improved upon. 70% is pretty good, and is much better than random guesses, but I think it is totally feasible that accuracies of 90% can be achieved by people, and so that is what the model should be going for. In addition, the issue where piano is being classified much less accurately than others remains an area for further research. In fact, once this area is cleared up, we might be seeing accuracies pretty close to the 90% range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas for Future Work\n",
    "\n",
    "I really enjoyed working on this project, so I think it is likely that I'll expand on it in the future. These here notes are as much for me as they are for you.\n",
    "\n",
    "First, I think more work could be done on the collection of useful data. When I ran some trials with much larger but somewhat skewed datasets, I could get accuracies up into the 90% range. Perhaps the issue with the piano would completely go away if only I had more piano data. Going hand in hand with that, some improvements on performance when reading in data would make the development process go much smoother.\n",
    "\n",
    "Along the same performance lines, I think that experimenting with machine learning packages such as tensorflow that utilize GPU optimizations for their algorithms could also help tremendously in development.\n",
    "\n",
    "Currently, the process only really works on very specific sorts of audio files. They have to be in the .wav format, they have to posess only a single channel, they have to be at a certain framerate, etc. I thought that perhaps including metadata into the algorithm as several additional datapoints could improve the generality of these methods. Or, perhaps, I could take the cowards way out and just use some sort of utility to convert other audio files into the correct format before applying my functions.\n",
    "\n",
    "I could probably waste an endless amount of time trying to optimize the shape of the networks and the preprocessing methods to come up with a method that increases accuracy. This is pretty low on the list of things to do in my opinion, but these changes are also quite easy to make.\n",
    "\n",
    "The diagnostic information that the CreateModel() method provides was instrumental in figuring out everything that I did. I think it would be nice if it provided even more information, perhaps some more things about the metadata of the data sets themselves. I believe that would prove useful in the creation of more advanced methods of classification.\n",
    "\n",
    "Finally, my next big ambition is to classify an audio file where multiple instruments are playing at once, and identify each one. Once I get the accuracy of this current method of classifying lone instruments up high enought, that is the next big step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
