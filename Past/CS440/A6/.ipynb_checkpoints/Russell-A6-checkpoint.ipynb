{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sean Russell*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will write and apply code that trains neural networks of various numbers of hidden layers and units in each hidden layer and returns results as specified below.  You will do this once for a regression problem and once for a classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [nn2.tar](http://www.cs.colostate.edu/~anderson/cs440/notebooks/nn2.tar) that was used in lecture and extract its contents, which are\n",
    "\n",
    "* `neuralnetworks.py`\n",
    "* `scaledconjugategradient.py`\n",
    "* `mlutils.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the following functions that train and evaluate neural network models.\n",
    "\n",
    "* `results = trainNNs(X, T, trainFraction, hiddenLayerStructures, numberRepetitions, numberIterations, classify)`\n",
    "\n",
    "The arguments to `trainNNs` are\n",
    "\n",
    "* `X` is a matrix of input data of shape `nSamples x nFeatures`\n",
    "* `T` is a matrix of target data of shape `nSamples x nOutputs`\n",
    "* `trainFraction` is fraction of samples to use as training data. 1-`trainFraction` is number of samples for testing data\n",
    "* `hiddenLayerStructures` is list of network architectures. For example, to test two networks, one with one hidden layer of 20 units, and one with 3 hidden layers with 5, 10, and 20 units in each layer, this argument would be `[[20], [5, 10, 20]]`.\n",
    "* `numberRepetitions` is number of times to train a neural network.  Calculate training and testing average performance (two separate averages) of this many training runs.\n",
    "* `numberIterations` is the number of iterations to run the scaled conjugate gradient algorithm when a neural network is trained.\n",
    "* `classify` is set to `True` if you are doing a classification problem, in which case `T` must be a single column of target class integers.\n",
    "\n",
    "This function returns `results` which is list with one element for each network structure tested.  Each element is a list containing \n",
    "\n",
    "* the hidden layer structure (as a list),\n",
    "* a list of training data performance for each repetition, \n",
    "* a list of testing data performance for each repetition, and\n",
    "* the number of seconds it took to run this many repetitions for this network structure.\n",
    "\n",
    "This function should follow these steps:\n",
    "\n",
    "  * For each network structure given in `hiddenLayerStructures`\n",
    "    * For numberRepetitions\n",
    "      * Use `ml.partition` to randomly partition X and T into training and testing sets.\n",
    "      * Create a neural network of the given structure\n",
    "      * Train it for numberIterations\n",
    "      * Use the trained network to produce outputs for the training and for the testing sets\n",
    "      * If classifying, calculate the fraction of samples incorrectly classified for training and testing sets.\n",
    "       Otherwise, calculate the RMSE of training and testing sets.\n",
    "      * Add the training and testing performance to a collection (such as a list) for this network structure\n",
    "    * Add to a collection of all results the hidden layer structure, lists of training performance and testing performance, and seconds taken to do these repetitions.\n",
    "  * return the collection of all results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also write the following two functions. `summarize(results)` returns a list of lists like `results` but with the list of training performances replaced by their mean and the list of testing performances replaced by their mean.   \n",
    "`bestNetwork(summary)` takes the output of `summarize(results)` and returns the best element of `results`, determined by the element that has the smallest test performance.\n",
    "\n",
    "* `summary = summarize(results)` where `results` is returned by `trainNNs` and `summary` is like `results` with the training and testing performance lists replaced by their means\n",
    "* `best = bestNetwork(summary)` where `summary` is returned by `summarize` and `best` is the best element of `summary`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a bunch of imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlutils as ml\n",
    "import neuralnetworks as nn\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heres the meat of the code. trainNNs trains and tests a bunch of networks all at once with different hidden layer structures and returns the performance of each different network structure. summarize takes these results and makes them a bit easier to read, and bestNetwork takes the summary and only returns the results for the best network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNNs(X, T, trainFraction, hiddenLayerStructures, numberRepetitions, numberIterations, classify=False):\n",
    "    results = []\n",
    "    for structure in hiddenLayerStructures:\n",
    "        result = []\n",
    "        trainingPerformance = []\n",
    "        testingPerformance = []\n",
    "        result.append(structure)\n",
    "        startTime = time.time()\n",
    "        for n in range(numberRepetitions):\n",
    "            trainX, trainT, testX, testT = ml.partition(X,T,[trainFraction,1-trainFraction],classify)\n",
    "            model = nn.NeuralNetworkClassifier(X.shape[1],structure,len(np.unique(T))) if classify else nn.NeuralNetwork(X.shape[1],structure,T.shape[1])\n",
    "            model.train(trainX, trainT, numberIterations)\n",
    "            predictedTrain = model.use(trainX)\n",
    "            predictedTest = model.use(testX)\n",
    "            RMSE = lambda actual, predicted: sqrt(mean_squared_error(actual, predicted))\n",
    "            trainError = 1 - ml.percentCorrect(predictedTrain,trainT) / 100 if classify else RMSE(trainT, predictedTrain)\n",
    "            testError = 1 - ml.percentCorrect(predictedTest,testT) / 100 if classify else RMSE(testT, predictedTest)\n",
    "            trainingPerformance.append(trainError)\n",
    "            testingPerformance.append(testError)\n",
    "        endTime = time.time()\n",
    "        result.append(trainingPerformance)\n",
    "        result.append(testingPerformance)\n",
    "        result.append(endTime - startTime)\n",
    "        results.append(result)  \n",
    "    return results\n",
    "\n",
    "def summarize(results):\n",
    "    results = copy.deepcopy(results)\n",
    "    for result in results:\n",
    "        result[1] = sum(result[1]) / len(result[1])\n",
    "        result[2] = sum(result[2]) / len(result[2])\n",
    "    return results\n",
    "\n",
    "def bestNetwork(summary):\n",
    "    bestResult = summary[0]\n",
    "    for result in summary:\n",
    "        if result[2] < bestResult[2]:\n",
    "            bestResult = result\n",
    "    return bestResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Regression Experiment\n",
    "\n",
    "From the UCI Machine Learning Repository, download the [Appliances energy prediction](http://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction) data.  You can do this by visiting the Data Folder for this data set, or just do this:\n",
    "\n",
    "     !wget http://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read this data into python.  One suggestion is to use the `loadtxt` function in the `numpy` package.  You may ignore the first column of each row which contains a data and time.  Also ignore the last two columns of random variables.  We will not use that in our modeling of this data.  You will also have to deal with the double quotes that surround every value in every field.  Read the first line of this file to get the names of the features.\n",
    "\n",
    "Once you have read this in correctly, you should see values like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(fileName, excludedColumns):\n",
    "    df = pd.read_csv(fileName)\n",
    "    for excluded in excludedColumns:\n",
    "        df.drop(excluded, axis=1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fileName = 'energydata_complete.csv'\n",
    "excludedColumns = ['date', 'rv1', 'rv2']\n",
    "df = readData(fileName, excludedColumns)\n",
    "names = list(df.axes[1])\n",
    "data = df.as_matrix()\n",
    "Xenergy = data[:,2:]\n",
    "Tenergy = data[:,:2]\n",
    "Xnames = names[2:]\n",
    "Tnames = names[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train several neural networks on all of this data for 100 iterations.  Plot the error trace (nnet.getErrorTrace()) to help you decide now many iterations might be needed.  100 may not be enough.  If for your larger networks the error is still decreasing after 100 iterations you should train all nets for more than 100 iterations.\n",
    "\n",
    "Now use your `trainNNs`, `summarize`, and `bestNetwork` functions on this data to investigate various network sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainNNs(Xenergy, Tenergy, 0.8, [0, 5, [5, 5], [10, 10]], 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 67.14380511599147, 67.26430089723117, 2.2673590183258057],\n",
       " [5, 65.27477821593422, 65.585980240998, 23.882287979125977],\n",
       " [[5, 5], 64.87599148368307, 66.06982609562651, 35.216299057006836],\n",
       " [[10, 10], 62.90730436756324, 64.00417527576994, 58.27176809310913]]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 10], 62.90730436756324, 64.00417527576994, 58.27176809310913]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestNetwork(summarize(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test at least 10 different hidden layer structures.  Larger numbers of layers and units may do the best on training data, but not on testing data. Why?\n",
    "\n",
    "Now train another network with your best hidden layer structure on 0.8 of the data and use the trained network on the testing data (the remaining 0.2 of the date).  As before use `ml.partition` to produce the training and testing sets.\n",
    "\n",
    "For the testing data, plot the predicted and actual `Appliances` energy use, and the predicted and actual `lights` energy use, in two separate plots.  Discuss what you see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Classification Experiment\n",
    "\n",
    "From the UCI Machine Learning Repository, download the [Anuran Calls (MFCCs)](http://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29) data.  You can do this by visiting the Data Folder for this data set, or just do this:\n",
    "\n",
    "     !wget 'http://archive.ics.uci.edu/ml/machine-learning-databases/00406/Anuran Calls (MFCCs).zip'\n",
    "     !unzip Anuran*zip\n",
    "     \n",
    "Read the data in the file `Frogs_MFCCs.csv` into python.  This will be a little tricky. Each line of the file is a sample of audio features plus three columns that label the sample by family, genus, and species. We will try to predict the species.  The tricky part is that the species is given as text.  We need to convert this to a target class, as an integer. The `numpy` function `unique` will come in handy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_14</th>\n",
       "      <th>MFCCs_15</th>\n",
       "      <th>MFCCs_16</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082245</td>\n",
       "      <td>0.135752</td>\n",
       "      <td>-0.024017</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022786</td>\n",
       "      <td>0.163320</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050791</td>\n",
       "      <td>0.207338</td>\n",
       "      <td>0.083536</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011567</td>\n",
       "      <td>0.100413</td>\n",
       "      <td>-0.050224</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037439</td>\n",
       "      <td>0.219153</td>\n",
       "      <td>0.062837</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.099704</td>\n",
       "      <td>-0.033408</td>\n",
       "      <td>0.349895</td>\n",
       "      <td>0.344535</td>\n",
       "      <td>0.247569</td>\n",
       "      <td>0.022407</td>\n",
       "      <td>-0.213767</td>\n",
       "      <td>-0.127916</td>\n",
       "      <td>0.277353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012486</td>\n",
       "      <td>0.180641</td>\n",
       "      <td>0.055242</td>\n",
       "      <td>-0.080487</td>\n",
       "      <td>-0.130089</td>\n",
       "      <td>-0.171478</td>\n",
       "      <td>-0.071569</td>\n",
       "      <td>0.077643</td>\n",
       "      <td>0.064903</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021676</td>\n",
       "      <td>-0.062075</td>\n",
       "      <td>0.318229</td>\n",
       "      <td>0.380439</td>\n",
       "      <td>0.179043</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>-0.252300</td>\n",
       "      <td>-0.167117</td>\n",
       "      <td>0.220027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027070</td>\n",
       "      <td>0.216923</td>\n",
       "      <td>0.064853</td>\n",
       "      <td>-0.046620</td>\n",
       "      <td>-0.055146</td>\n",
       "      <td>-0.085972</td>\n",
       "      <td>-0.009127</td>\n",
       "      <td>0.065630</td>\n",
       "      <td>0.044040</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.145130</td>\n",
       "      <td>-0.033660</td>\n",
       "      <td>0.284166</td>\n",
       "      <td>0.279537</td>\n",
       "      <td>0.175211</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>-0.183329</td>\n",
       "      <td>-0.158483</td>\n",
       "      <td>0.192567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009015</td>\n",
       "      <td>0.184266</td>\n",
       "      <td>0.075654</td>\n",
       "      <td>-0.055978</td>\n",
       "      <td>-0.048219</td>\n",
       "      <td>-0.056637</td>\n",
       "      <td>-0.022419</td>\n",
       "      <td>0.070085</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271326</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>0.375738</td>\n",
       "      <td>0.385432</td>\n",
       "      <td>0.272457</td>\n",
       "      <td>0.098192</td>\n",
       "      <td>-0.173730</td>\n",
       "      <td>-0.157857</td>\n",
       "      <td>0.207181</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044984</td>\n",
       "      <td>0.064425</td>\n",
       "      <td>-0.032167</td>\n",
       "      <td>-0.120723</td>\n",
       "      <td>-0.112607</td>\n",
       "      <td>-0.156933</td>\n",
       "      <td>-0.118527</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120565</td>\n",
       "      <td>-0.107235</td>\n",
       "      <td>0.316555</td>\n",
       "      <td>0.364437</td>\n",
       "      <td>0.307757</td>\n",
       "      <td>0.025992</td>\n",
       "      <td>-0.294179</td>\n",
       "      <td>-0.223236</td>\n",
       "      <td>0.268435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042678</td>\n",
       "      <td>0.236484</td>\n",
       "      <td>0.053436</td>\n",
       "      <td>-0.051073</td>\n",
       "      <td>-0.052568</td>\n",
       "      <td>-0.111338</td>\n",
       "      <td>-0.040014</td>\n",
       "      <td>0.090204</td>\n",
       "      <td>0.088025</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.148539</td>\n",
       "      <td>-0.096910</td>\n",
       "      <td>0.257523</td>\n",
       "      <td>0.260881</td>\n",
       "      <td>0.312603</td>\n",
       "      <td>0.134134</td>\n",
       "      <td>-0.216262</td>\n",
       "      <td>-0.189334</td>\n",
       "      <td>0.261960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051362</td>\n",
       "      <td>0.221784</td>\n",
       "      <td>0.111884</td>\n",
       "      <td>-0.034082</td>\n",
       "      <td>-0.120716</td>\n",
       "      <td>-0.100800</td>\n",
       "      <td>-0.001992</td>\n",
       "      <td>0.111462</td>\n",
       "      <td>0.103637</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.277948</td>\n",
       "      <td>0.091657</td>\n",
       "      <td>0.331656</td>\n",
       "      <td>0.307372</td>\n",
       "      <td>0.257359</td>\n",
       "      <td>0.065702</td>\n",
       "      <td>-0.191860</td>\n",
       "      <td>-0.133537</td>\n",
       "      <td>0.220020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025145</td>\n",
       "      <td>0.119870</td>\n",
       "      <td>-0.018260</td>\n",
       "      <td>-0.119167</td>\n",
       "      <td>-0.110900</td>\n",
       "      <td>-0.112485</td>\n",
       "      <td>-0.053184</td>\n",
       "      <td>0.044291</td>\n",
       "      <td>-0.011456</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106109</td>\n",
       "      <td>-0.025790</td>\n",
       "      <td>0.358875</td>\n",
       "      <td>0.297543</td>\n",
       "      <td>0.244335</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>-0.288733</td>\n",
       "      <td>-0.146731</td>\n",
       "      <td>0.314207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016204</td>\n",
       "      <td>0.198509</td>\n",
       "      <td>0.078510</td>\n",
       "      <td>-0.062939</td>\n",
       "      <td>-0.071182</td>\n",
       "      <td>-0.066827</td>\n",
       "      <td>-0.028048</td>\n",
       "      <td>0.058353</td>\n",
       "      <td>0.064368</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.126523</td>\n",
       "      <td>-0.040482</td>\n",
       "      <td>0.341129</td>\n",
       "      <td>0.381446</td>\n",
       "      <td>0.261154</td>\n",
       "      <td>-0.017049</td>\n",
       "      <td>-0.294064</td>\n",
       "      <td>-0.222278</td>\n",
       "      <td>0.282338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039459</td>\n",
       "      <td>0.202870</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>-0.071544</td>\n",
       "      <td>-0.060630</td>\n",
       "      <td>-0.067230</td>\n",
       "      <td>-0.038196</td>\n",
       "      <td>0.070127</td>\n",
       "      <td>0.048440</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.267687</td>\n",
       "      <td>0.099327</td>\n",
       "      <td>0.510454</td>\n",
       "      <td>0.511468</td>\n",
       "      <td>0.317788</td>\n",
       "      <td>0.067992</td>\n",
       "      <td>-0.202826</td>\n",
       "      <td>-0.142236</td>\n",
       "      <td>0.235510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025456</td>\n",
       "      <td>0.099738</td>\n",
       "      <td>-0.015500</td>\n",
       "      <td>-0.138830</td>\n",
       "      <td>-0.139922</td>\n",
       "      <td>-0.126448</td>\n",
       "      <td>-0.067570</td>\n",
       "      <td>0.057888</td>\n",
       "      <td>-0.011998</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.137623</td>\n",
       "      <td>-0.085808</td>\n",
       "      <td>0.322446</td>\n",
       "      <td>0.344695</td>\n",
       "      <td>0.285642</td>\n",
       "      <td>0.056517</td>\n",
       "      <td>-0.314418</td>\n",
       "      <td>-0.252324</td>\n",
       "      <td>0.288897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041608</td>\n",
       "      <td>0.236627</td>\n",
       "      <td>0.071433</td>\n",
       "      <td>-0.058694</td>\n",
       "      <td>-0.072913</td>\n",
       "      <td>-0.064263</td>\n",
       "      <td>0.022455</td>\n",
       "      <td>0.130752</td>\n",
       "      <td>0.074132</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263944</td>\n",
       "      <td>0.090358</td>\n",
       "      <td>0.368888</td>\n",
       "      <td>0.356645</td>\n",
       "      <td>0.252806</td>\n",
       "      <td>0.063921</td>\n",
       "      <td>-0.155007</td>\n",
       "      <td>-0.137743</td>\n",
       "      <td>0.200262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012428</td>\n",
       "      <td>0.094166</td>\n",
       "      <td>-0.013232</td>\n",
       "      <td>-0.074168</td>\n",
       "      <td>-0.083995</td>\n",
       "      <td>-0.104413</td>\n",
       "      <td>-0.071431</td>\n",
       "      <td>0.028842</td>\n",
       "      <td>0.019180</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.146299</td>\n",
       "      <td>-0.075174</td>\n",
       "      <td>0.291935</td>\n",
       "      <td>0.367094</td>\n",
       "      <td>0.268947</td>\n",
       "      <td>0.054049</td>\n",
       "      <td>-0.242952</td>\n",
       "      <td>-0.232617</td>\n",
       "      <td>0.235722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015118</td>\n",
       "      <td>0.151180</td>\n",
       "      <td>0.029547</td>\n",
       "      <td>-0.051154</td>\n",
       "      <td>-0.038580</td>\n",
       "      <td>-0.022396</td>\n",
       "      <td>-0.018891</td>\n",
       "      <td>0.051480</td>\n",
       "      <td>0.031871</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.179298</td>\n",
       "      <td>-0.038306</td>\n",
       "      <td>0.319636</td>\n",
       "      <td>0.383029</td>\n",
       "      <td>0.275313</td>\n",
       "      <td>0.099083</td>\n",
       "      <td>-0.207998</td>\n",
       "      <td>-0.219215</td>\n",
       "      <td>0.182845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037064</td>\n",
       "      <td>0.132052</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>-0.110969</td>\n",
       "      <td>-0.105833</td>\n",
       "      <td>-0.115237</td>\n",
       "      <td>-0.012819</td>\n",
       "      <td>0.083194</td>\n",
       "      <td>0.052101</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.273218</td>\n",
       "      <td>-0.234703</td>\n",
       "      <td>-0.079620</td>\n",
       "      <td>0.159811</td>\n",
       "      <td>0.416406</td>\n",
       "      <td>0.368838</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>-0.171288</td>\n",
       "      <td>-0.115424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150033</td>\n",
       "      <td>-0.030006</td>\n",
       "      <td>-0.231130</td>\n",
       "      <td>-0.253103</td>\n",
       "      <td>-0.154244</td>\n",
       "      <td>-0.002606</td>\n",
       "      <td>0.092999</td>\n",
       "      <td>0.091724</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>0.317772</td>\n",
       "      <td>0.293484</td>\n",
       "      <td>0.185684</td>\n",
       "      <td>0.044063</td>\n",
       "      <td>-0.169936</td>\n",
       "      <td>-0.121461</td>\n",
       "      <td>0.237437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.163426</td>\n",
       "      <td>0.047060</td>\n",
       "      <td>-0.045409</td>\n",
       "      <td>-0.067118</td>\n",
       "      <td>-0.047625</td>\n",
       "      <td>-0.005875</td>\n",
       "      <td>0.053107</td>\n",
       "      <td>0.030669</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230999</td>\n",
       "      <td>0.135657</td>\n",
       "      <td>0.431966</td>\n",
       "      <td>0.403423</td>\n",
       "      <td>0.276571</td>\n",
       "      <td>0.060464</td>\n",
       "      <td>-0.192200</td>\n",
       "      <td>-0.187348</td>\n",
       "      <td>0.180486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092437</td>\n",
       "      <td>0.111833</td>\n",
       "      <td>-0.047993</td>\n",
       "      <td>-0.163367</td>\n",
       "      <td>-0.170739</td>\n",
       "      <td>-0.169508</td>\n",
       "      <td>-0.112446</td>\n",
       "      <td>0.065072</td>\n",
       "      <td>0.050254</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.145109</td>\n",
       "      <td>-0.035846</td>\n",
       "      <td>0.282707</td>\n",
       "      <td>0.291044</td>\n",
       "      <td>0.206862</td>\n",
       "      <td>0.048627</td>\n",
       "      <td>-0.172111</td>\n",
       "      <td>-0.115698</td>\n",
       "      <td>0.251256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049506</td>\n",
       "      <td>0.205311</td>\n",
       "      <td>0.066123</td>\n",
       "      <td>-0.044077</td>\n",
       "      <td>-0.067219</td>\n",
       "      <td>-0.058514</td>\n",
       "      <td>-0.001358</td>\n",
       "      <td>0.082058</td>\n",
       "      <td>0.045492</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235682</td>\n",
       "      <td>0.029241</td>\n",
       "      <td>0.349117</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.290697</td>\n",
       "      <td>0.081008</td>\n",
       "      <td>-0.193793</td>\n",
       "      <td>-0.151462</td>\n",
       "      <td>0.212130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>0.150663</td>\n",
       "      <td>-0.028506</td>\n",
       "      <td>-0.158932</td>\n",
       "      <td>-0.098565</td>\n",
       "      <td>-0.078413</td>\n",
       "      <td>-0.043410</td>\n",
       "      <td>0.033478</td>\n",
       "      <td>-0.006953</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.146944</td>\n",
       "      <td>-0.009583</td>\n",
       "      <td>0.352534</td>\n",
       "      <td>0.313435</td>\n",
       "      <td>0.197599</td>\n",
       "      <td>0.015352</td>\n",
       "      <td>-0.216492</td>\n",
       "      <td>-0.133865</td>\n",
       "      <td>0.278309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060910</td>\n",
       "      <td>0.187107</td>\n",
       "      <td>0.030893</td>\n",
       "      <td>-0.043595</td>\n",
       "      <td>-0.052536</td>\n",
       "      <td>-0.024106</td>\n",
       "      <td>0.016081</td>\n",
       "      <td>0.062506</td>\n",
       "      <td>0.042285</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.233512</td>\n",
       "      <td>0.067249</td>\n",
       "      <td>0.352310</td>\n",
       "      <td>0.316899</td>\n",
       "      <td>0.220584</td>\n",
       "      <td>0.044433</td>\n",
       "      <td>-0.172653</td>\n",
       "      <td>-0.127641</td>\n",
       "      <td>0.190017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007142</td>\n",
       "      <td>0.124032</td>\n",
       "      <td>-0.039927</td>\n",
       "      <td>-0.105466</td>\n",
       "      <td>-0.070941</td>\n",
       "      <td>-0.085853</td>\n",
       "      <td>-0.025053</td>\n",
       "      <td>0.055194</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.172672</td>\n",
       "      <td>-0.037870</td>\n",
       "      <td>0.301100</td>\n",
       "      <td>0.303533</td>\n",
       "      <td>0.203767</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>-0.197260</td>\n",
       "      <td>-0.124021</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017556</td>\n",
       "      <td>0.174776</td>\n",
       "      <td>0.033374</td>\n",
       "      <td>-0.078277</td>\n",
       "      <td>-0.023172</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>0.063916</td>\n",
       "      <td>0.047634</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.198494</td>\n",
       "      <td>0.078718</td>\n",
       "      <td>0.478231</td>\n",
       "      <td>0.425219</td>\n",
       "      <td>0.257916</td>\n",
       "      <td>0.049410</td>\n",
       "      <td>-0.146034</td>\n",
       "      <td>-0.127461</td>\n",
       "      <td>0.170725</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100023</td>\n",
       "      <td>0.083705</td>\n",
       "      <td>-0.061133</td>\n",
       "      <td>-0.172904</td>\n",
       "      <td>-0.164822</td>\n",
       "      <td>-0.152341</td>\n",
       "      <td>-0.068851</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>-0.009821</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165998</td>\n",
       "      <td>-0.004175</td>\n",
       "      <td>0.289963</td>\n",
       "      <td>0.295084</td>\n",
       "      <td>0.224001</td>\n",
       "      <td>0.085586</td>\n",
       "      <td>-0.180608</td>\n",
       "      <td>-0.169064</td>\n",
       "      <td>0.221722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041270</td>\n",
       "      <td>0.166617</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>-0.067536</td>\n",
       "      <td>-0.084953</td>\n",
       "      <td>-0.116397</td>\n",
       "      <td>-0.008499</td>\n",
       "      <td>0.101151</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.155225</td>\n",
       "      <td>-0.063337</td>\n",
       "      <td>0.231699</td>\n",
       "      <td>0.284514</td>\n",
       "      <td>0.219596</td>\n",
       "      <td>0.038581</td>\n",
       "      <td>-0.183926</td>\n",
       "      <td>-0.108442</td>\n",
       "      <td>0.245208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008401</td>\n",
       "      <td>0.161657</td>\n",
       "      <td>0.025020</td>\n",
       "      <td>-0.072937</td>\n",
       "      <td>-0.018316</td>\n",
       "      <td>-0.034315</td>\n",
       "      <td>-0.029563</td>\n",
       "      <td>0.051715</td>\n",
       "      <td>0.023925</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7165</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.132365</td>\n",
       "      <td>0.503936</td>\n",
       "      <td>0.271392</td>\n",
       "      <td>-0.042392</td>\n",
       "      <td>0.024487</td>\n",
       "      <td>0.080317</td>\n",
       "      <td>0.112706</td>\n",
       "      <td>-0.071058</td>\n",
       "      <td>-0.114414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010658</td>\n",
       "      <td>-0.025423</td>\n",
       "      <td>-0.009011</td>\n",
       "      <td>-0.006677</td>\n",
       "      <td>-0.070338</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.032534</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7166</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165383</td>\n",
       "      <td>0.408082</td>\n",
       "      <td>0.270187</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.025284</td>\n",
       "      <td>0.120438</td>\n",
       "      <td>0.042605</td>\n",
       "      <td>-0.053960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>-0.033569</td>\n",
       "      <td>-0.024850</td>\n",
       "      <td>0.007785</td>\n",
       "      <td>-0.002231</td>\n",
       "      <td>0.020593</td>\n",
       "      <td>0.014499</td>\n",
       "      <td>0.008208</td>\n",
       "      <td>0.018023</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7167</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.411916</td>\n",
       "      <td>0.322796</td>\n",
       "      <td>0.344183</td>\n",
       "      <td>0.333873</td>\n",
       "      <td>0.094867</td>\n",
       "      <td>-0.230982</td>\n",
       "      <td>0.276750</td>\n",
       "      <td>0.232506</td>\n",
       "      <td>-0.372219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138802</td>\n",
       "      <td>-0.128108</td>\n",
       "      <td>-0.250080</td>\n",
       "      <td>0.029924</td>\n",
       "      <td>0.031286</td>\n",
       "      <td>-0.038367</td>\n",
       "      <td>-0.007837</td>\n",
       "      <td>0.102445</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7168</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.404936</td>\n",
       "      <td>0.726247</td>\n",
       "      <td>0.167376</td>\n",
       "      <td>-0.169260</td>\n",
       "      <td>0.112154</td>\n",
       "      <td>0.050805</td>\n",
       "      <td>0.078670</td>\n",
       "      <td>-0.243258</td>\n",
       "      <td>-0.120933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244978</td>\n",
       "      <td>0.052956</td>\n",
       "      <td>-0.204797</td>\n",
       "      <td>0.090483</td>\n",
       "      <td>0.126233</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>0.059531</td>\n",
       "      <td>0.050905</td>\n",
       "      <td>-0.026956</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7169</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.209224</td>\n",
       "      <td>0.625373</td>\n",
       "      <td>0.246565</td>\n",
       "      <td>-0.108078</td>\n",
       "      <td>0.174846</td>\n",
       "      <td>0.100347</td>\n",
       "      <td>0.035056</td>\n",
       "      <td>-0.149125</td>\n",
       "      <td>-0.099348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062459</td>\n",
       "      <td>0.022637</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>-0.041610</td>\n",
       "      <td>-0.039468</td>\n",
       "      <td>0.086045</td>\n",
       "      <td>0.071944</td>\n",
       "      <td>-0.021574</td>\n",
       "      <td>0.036031</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7170</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.242842</td>\n",
       "      <td>0.516606</td>\n",
       "      <td>0.263976</td>\n",
       "      <td>-0.040676</td>\n",
       "      <td>0.052257</td>\n",
       "      <td>0.055201</td>\n",
       "      <td>0.125361</td>\n",
       "      <td>-0.023455</td>\n",
       "      <td>-0.064192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055126</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>-0.014339</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>-0.013307</td>\n",
       "      <td>-0.001609</td>\n",
       "      <td>0.022170</td>\n",
       "      <td>0.014327</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7171</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.153789</td>\n",
       "      <td>0.522557</td>\n",
       "      <td>0.267617</td>\n",
       "      <td>-0.043499</td>\n",
       "      <td>0.034436</td>\n",
       "      <td>0.081305</td>\n",
       "      <td>0.113272</td>\n",
       "      <td>-0.034906</td>\n",
       "      <td>-0.055563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014452</td>\n",
       "      <td>-0.002528</td>\n",
       "      <td>-0.010471</td>\n",
       "      <td>-0.005648</td>\n",
       "      <td>-0.028727</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.033687</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.014982</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7172</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.266711</td>\n",
       "      <td>0.735734</td>\n",
       "      <td>0.233772</td>\n",
       "      <td>-0.075867</td>\n",
       "      <td>0.140193</td>\n",
       "      <td>0.080212</td>\n",
       "      <td>0.119675</td>\n",
       "      <td>-0.038130</td>\n",
       "      <td>-0.033289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034721</td>\n",
       "      <td>0.030751</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>-0.027436</td>\n",
       "      <td>-0.007999</td>\n",
       "      <td>0.058854</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>0.019086</td>\n",
       "      <td>0.090131</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.183156</td>\n",
       "      <td>0.506970</td>\n",
       "      <td>0.247162</td>\n",
       "      <td>-0.048503</td>\n",
       "      <td>0.041090</td>\n",
       "      <td>0.093071</td>\n",
       "      <td>0.109081</td>\n",
       "      <td>-0.049473</td>\n",
       "      <td>-0.044991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017840</td>\n",
       "      <td>0.019535</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>-0.008959</td>\n",
       "      <td>-0.034239</td>\n",
       "      <td>0.036489</td>\n",
       "      <td>0.042205</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.197679</td>\n",
       "      <td>0.553775</td>\n",
       "      <td>0.269271</td>\n",
       "      <td>-0.056261</td>\n",
       "      <td>0.062528</td>\n",
       "      <td>0.061367</td>\n",
       "      <td>0.094837</td>\n",
       "      <td>-0.047792</td>\n",
       "      <td>-0.063015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018963</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>0.015442</td>\n",
       "      <td>0.021719</td>\n",
       "      <td>-0.041396</td>\n",
       "      <td>-0.013619</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.017903</td>\n",
       "      <td>0.022108</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.673025</td>\n",
       "      <td>-0.279960</td>\n",
       "      <td>0.065945</td>\n",
       "      <td>0.086890</td>\n",
       "      <td>0.469024</td>\n",
       "      <td>0.088019</td>\n",
       "      <td>-0.197498</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>0.096919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112334</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>-0.033484</td>\n",
       "      <td>0.052054</td>\n",
       "      <td>0.114138</td>\n",
       "      <td>0.069353</td>\n",
       "      <td>0.050519</td>\n",
       "      <td>-0.069281</td>\n",
       "      <td>-0.106642</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.574239</td>\n",
       "      <td>-0.258302</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>0.078566</td>\n",
       "      <td>0.402132</td>\n",
       "      <td>0.093501</td>\n",
       "      <td>-0.146350</td>\n",
       "      <td>0.040779</td>\n",
       "      <td>0.105841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075514</td>\n",
       "      <td>0.012561</td>\n",
       "      <td>-0.001182</td>\n",
       "      <td>0.062850</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>0.019184</td>\n",
       "      <td>0.027745</td>\n",
       "      <td>-0.109677</td>\n",
       "      <td>-0.131287</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.515567</td>\n",
       "      <td>-0.219812</td>\n",
       "      <td>0.118473</td>\n",
       "      <td>0.106919</td>\n",
       "      <td>0.471155</td>\n",
       "      <td>0.121196</td>\n",
       "      <td>-0.136494</td>\n",
       "      <td>0.027486</td>\n",
       "      <td>0.106110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038105</td>\n",
       "      <td>0.029394</td>\n",
       "      <td>-0.022552</td>\n",
       "      <td>0.049024</td>\n",
       "      <td>0.109761</td>\n",
       "      <td>0.043604</td>\n",
       "      <td>0.047369</td>\n",
       "      <td>-0.018168</td>\n",
       "      <td>-0.085380</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7178</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.614409</td>\n",
       "      <td>-0.261315</td>\n",
       "      <td>0.051138</td>\n",
       "      <td>0.062119</td>\n",
       "      <td>0.501500</td>\n",
       "      <td>0.096506</td>\n",
       "      <td>-0.155093</td>\n",
       "      <td>0.035657</td>\n",
       "      <td>0.121933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049190</td>\n",
       "      <td>0.037494</td>\n",
       "      <td>-0.028617</td>\n",
       "      <td>0.048454</td>\n",
       "      <td>0.072420</td>\n",
       "      <td>0.017823</td>\n",
       "      <td>-0.021418</td>\n",
       "      <td>-0.094280</td>\n",
       "      <td>-0.091600</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7179</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.578837</td>\n",
       "      <td>-0.331501</td>\n",
       "      <td>0.105921</td>\n",
       "      <td>0.089931</td>\n",
       "      <td>0.456617</td>\n",
       "      <td>0.079131</td>\n",
       "      <td>-0.133406</td>\n",
       "      <td>0.056485</td>\n",
       "      <td>0.093265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059179</td>\n",
       "      <td>0.029580</td>\n",
       "      <td>0.030742</td>\n",
       "      <td>0.079075</td>\n",
       "      <td>0.125759</td>\n",
       "      <td>0.044132</td>\n",
       "      <td>0.017652</td>\n",
       "      <td>-0.077831</td>\n",
       "      <td>-0.132563</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7180</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.528595</td>\n",
       "      <td>-0.208051</td>\n",
       "      <td>0.103669</td>\n",
       "      <td>0.086537</td>\n",
       "      <td>0.408476</td>\n",
       "      <td>0.069610</td>\n",
       "      <td>-0.155217</td>\n",
       "      <td>0.080287</td>\n",
       "      <td>0.127136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072345</td>\n",
       "      <td>0.008949</td>\n",
       "      <td>-0.041878</td>\n",
       "      <td>0.053063</td>\n",
       "      <td>0.085869</td>\n",
       "      <td>0.020705</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>-0.072003</td>\n",
       "      <td>-0.121693</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7181</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.442139</td>\n",
       "      <td>-0.328404</td>\n",
       "      <td>0.031452</td>\n",
       "      <td>0.056017</td>\n",
       "      <td>0.424856</td>\n",
       "      <td>0.073288</td>\n",
       "      <td>-0.140148</td>\n",
       "      <td>0.043070</td>\n",
       "      <td>0.087675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088273</td>\n",
       "      <td>-0.009950</td>\n",
       "      <td>-0.034092</td>\n",
       "      <td>0.024943</td>\n",
       "      <td>0.068279</td>\n",
       "      <td>0.015953</td>\n",
       "      <td>0.058530</td>\n",
       "      <td>-0.009746</td>\n",
       "      <td>-0.080940</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7182</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.616029</td>\n",
       "      <td>-0.302357</td>\n",
       "      <td>0.063417</td>\n",
       "      <td>0.095671</td>\n",
       "      <td>0.439930</td>\n",
       "      <td>0.069414</td>\n",
       "      <td>-0.145534</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042672</td>\n",
       "      <td>0.051841</td>\n",
       "      <td>0.023079</td>\n",
       "      <td>0.056971</td>\n",
       "      <td>0.037285</td>\n",
       "      <td>0.023818</td>\n",
       "      <td>0.042104</td>\n",
       "      <td>-0.035603</td>\n",
       "      <td>-0.097343</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.547168</td>\n",
       "      <td>-0.266780</td>\n",
       "      <td>0.056115</td>\n",
       "      <td>0.048947</td>\n",
       "      <td>0.423631</td>\n",
       "      <td>0.081924</td>\n",
       "      <td>-0.184252</td>\n",
       "      <td>0.024682</td>\n",
       "      <td>0.111803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057318</td>\n",
       "      <td>0.013367</td>\n",
       "      <td>-0.022609</td>\n",
       "      <td>0.049831</td>\n",
       "      <td>0.115522</td>\n",
       "      <td>0.051333</td>\n",
       "      <td>0.019697</td>\n",
       "      <td>-0.061764</td>\n",
       "      <td>-0.078648</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.520958</td>\n",
       "      <td>-0.258779</td>\n",
       "      <td>-0.070416</td>\n",
       "      <td>-0.025129</td>\n",
       "      <td>0.447967</td>\n",
       "      <td>0.180033</td>\n",
       "      <td>-0.062297</td>\n",
       "      <td>0.032410</td>\n",
       "      <td>-0.005379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095316</td>\n",
       "      <td>0.055439</td>\n",
       "      <td>0.056085</td>\n",
       "      <td>0.027392</td>\n",
       "      <td>0.019266</td>\n",
       "      <td>-0.057772</td>\n",
       "      <td>0.037710</td>\n",
       "      <td>0.047717</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.512794</td>\n",
       "      <td>0.056322</td>\n",
       "      <td>0.259677</td>\n",
       "      <td>0.030140</td>\n",
       "      <td>0.369783</td>\n",
       "      <td>-0.117154</td>\n",
       "      <td>-0.189292</td>\n",
       "      <td>0.248948</td>\n",
       "      <td>0.193566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127350</td>\n",
       "      <td>0.123271</td>\n",
       "      <td>-0.088578</td>\n",
       "      <td>0.096589</td>\n",
       "      <td>0.255261</td>\n",
       "      <td>0.047039</td>\n",
       "      <td>-0.016643</td>\n",
       "      <td>-0.046598</td>\n",
       "      <td>-0.055862</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.591520</td>\n",
       "      <td>-0.268901</td>\n",
       "      <td>0.050042</td>\n",
       "      <td>0.116960</td>\n",
       "      <td>0.444706</td>\n",
       "      <td>0.059268</td>\n",
       "      <td>-0.158389</td>\n",
       "      <td>0.066648</td>\n",
       "      <td>0.083924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072221</td>\n",
       "      <td>0.022283</td>\n",
       "      <td>-0.012293</td>\n",
       "      <td>0.074444</td>\n",
       "      <td>0.117996</td>\n",
       "      <td>0.045522</td>\n",
       "      <td>0.050734</td>\n",
       "      <td>-0.034757</td>\n",
       "      <td>-0.085131</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.507564</td>\n",
       "      <td>-0.249969</td>\n",
       "      <td>0.031781</td>\n",
       "      <td>-0.079888</td>\n",
       "      <td>0.484274</td>\n",
       "      <td>0.125143</td>\n",
       "      <td>-0.069555</td>\n",
       "      <td>0.114265</td>\n",
       "      <td>0.099647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058002</td>\n",
       "      <td>0.132482</td>\n",
       "      <td>-0.016865</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>0.111998</td>\n",
       "      <td>0.015886</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>-0.021933</td>\n",
       "      <td>-0.069692</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7188</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.512599</td>\n",
       "      <td>-0.171956</td>\n",
       "      <td>0.325813</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.421567</td>\n",
       "      <td>-0.123749</td>\n",
       "      <td>-0.298284</td>\n",
       "      <td>0.089382</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.094519</td>\n",
       "      <td>-0.007756</td>\n",
       "      <td>0.021225</td>\n",
       "      <td>0.157321</td>\n",
       "      <td>0.042847</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>-0.013693</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.558546</td>\n",
       "      <td>-0.238442</td>\n",
       "      <td>0.066527</td>\n",
       "      <td>0.123090</td>\n",
       "      <td>0.395953</td>\n",
       "      <td>0.066522</td>\n",
       "      <td>-0.152216</td>\n",
       "      <td>0.078294</td>\n",
       "      <td>0.094184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071421</td>\n",
       "      <td>0.054151</td>\n",
       "      <td>0.015341</td>\n",
       "      <td>0.034202</td>\n",
       "      <td>0.040540</td>\n",
       "      <td>-0.003755</td>\n",
       "      <td>0.036059</td>\n",
       "      <td>-0.031853</td>\n",
       "      <td>-0.090206</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.554504</td>\n",
       "      <td>-0.337717</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.443451</td>\n",
       "      <td>0.093889</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>0.081075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059364</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>-0.000861</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>0.071001</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>-0.021860</td>\n",
       "      <td>-0.079860</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.517273</td>\n",
       "      <td>-0.370574</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>0.068097</td>\n",
       "      <td>0.402890</td>\n",
       "      <td>0.096628</td>\n",
       "      <td>-0.116460</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.089034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105600</td>\n",
       "      <td>0.030767</td>\n",
       "      <td>0.006457</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.068978</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>-0.101892</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.582557</td>\n",
       "      <td>-0.343237</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.064179</td>\n",
       "      <td>0.385596</td>\n",
       "      <td>0.114905</td>\n",
       "      <td>-0.103317</td>\n",
       "      <td>0.070370</td>\n",
       "      <td>0.081317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078615</td>\n",
       "      <td>0.024861</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.077771</td>\n",
       "      <td>-0.009688</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>-0.080425</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.519497</td>\n",
       "      <td>-0.307553</td>\n",
       "      <td>-0.004922</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>0.086866</td>\n",
       "      <td>-0.115799</td>\n",
       "      <td>0.056979</td>\n",
       "      <td>0.089316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075320</td>\n",
       "      <td>0.022903</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.051796</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.017963</td>\n",
       "      <td>0.041803</td>\n",
       "      <td>-0.027911</td>\n",
       "      <td>-0.096895</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.508833</td>\n",
       "      <td>-0.324106</td>\n",
       "      <td>0.062068</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>0.397188</td>\n",
       "      <td>0.094596</td>\n",
       "      <td>-0.117672</td>\n",
       "      <td>0.058874</td>\n",
       "      <td>0.076180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073415</td>\n",
       "      <td>0.042517</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.061455</td>\n",
       "      <td>0.072983</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.031560</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>-0.087910</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7195 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0          1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1          1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2          1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3          1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4          1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "5          1.0  0.099704 -0.033408  0.349895  0.344535  0.247569  0.022407   \n",
       "6          1.0  0.021676 -0.062075  0.318229  0.380439  0.179043 -0.041667   \n",
       "7          1.0  0.145130 -0.033660  0.284166  0.279537  0.175211  0.005791   \n",
       "8          1.0  0.271326  0.027777  0.375738  0.385432  0.272457  0.098192   \n",
       "9          1.0  0.120565 -0.107235  0.316555  0.364437  0.307757  0.025992   \n",
       "10         1.0  0.148539 -0.096910  0.257523  0.260881  0.312603  0.134134   \n",
       "11         1.0  0.277948  0.091657  0.331656  0.307372  0.257359  0.065702   \n",
       "12         1.0  0.106109 -0.025790  0.358875  0.297543  0.244335  0.016446   \n",
       "13         1.0  0.126523 -0.040482  0.341129  0.381446  0.261154 -0.017049   \n",
       "14         1.0  0.267687  0.099327  0.510454  0.511468  0.317788  0.067992   \n",
       "15         1.0  0.137623 -0.085808  0.322446  0.344695  0.285642  0.056517   \n",
       "16         1.0  0.263944  0.090358  0.368888  0.356645  0.252806  0.063921   \n",
       "17         1.0  0.146299 -0.075174  0.291935  0.367094  0.268947  0.054049   \n",
       "18         1.0  0.179298 -0.038306  0.319636  0.383029  0.275313  0.099083   \n",
       "19         1.0  0.273218 -0.234703 -0.079620  0.159811  0.416406  0.368838   \n",
       "20         1.0  0.196429  0.009021  0.317772  0.293484  0.185684  0.044063   \n",
       "21         1.0  0.230999  0.135657  0.431966  0.403423  0.276571  0.060464   \n",
       "22         1.0  0.145109 -0.035846  0.282707  0.291044  0.206862  0.048627   \n",
       "23         1.0  0.235682  0.029241  0.349117  0.355932  0.290697  0.081008   \n",
       "24         1.0  0.146944 -0.009583  0.352534  0.313435  0.197599  0.015352   \n",
       "25         1.0  0.233512  0.067249  0.352310  0.316899  0.220584  0.044433   \n",
       "26         1.0  0.172672 -0.037870  0.301100  0.303533  0.203767  0.017798   \n",
       "27         1.0  0.198494  0.078718  0.478231  0.425219  0.257916  0.049410   \n",
       "28         1.0  0.165998 -0.004175  0.289963  0.295084  0.224001  0.085586   \n",
       "29         1.0  0.155225 -0.063337  0.231699  0.284514  0.219596  0.038581   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7165       1.0  0.132365  0.503936  0.271392 -0.042392  0.024487  0.080317   \n",
       "7166       1.0  0.165383  0.408082  0.270187  0.015300  0.019000  0.025284   \n",
       "7167       1.0  0.411916  0.322796  0.344183  0.333873  0.094867 -0.230982   \n",
       "7168       1.0  0.404936  0.726247  0.167376 -0.169260  0.112154  0.050805   \n",
       "7169       1.0  0.209224  0.625373  0.246565 -0.108078  0.174846  0.100347   \n",
       "7170       1.0  0.242842  0.516606  0.263976 -0.040676  0.052257  0.055201   \n",
       "7171       1.0  0.153789  0.522557  0.267617 -0.043499  0.034436  0.081305   \n",
       "7172       1.0  0.266711  0.735734  0.233772 -0.075867  0.140193  0.080212   \n",
       "7173       1.0  0.183156  0.506970  0.247162 -0.048503  0.041090  0.093071   \n",
       "7174       1.0  0.197679  0.553775  0.269271 -0.056261  0.062528  0.061367   \n",
       "7175       1.0 -0.673025 -0.279960  0.065945  0.086890  0.469024  0.088019   \n",
       "7176       1.0 -0.574239 -0.258302  0.007644  0.078566  0.402132  0.093501   \n",
       "7177       1.0 -0.515567 -0.219812  0.118473  0.106919  0.471155  0.121196   \n",
       "7178       1.0 -0.614409 -0.261315  0.051138  0.062119  0.501500  0.096506   \n",
       "7179       1.0 -0.578837 -0.331501  0.105921  0.089931  0.456617  0.079131   \n",
       "7180       1.0 -0.528595 -0.208051  0.103669  0.086537  0.408476  0.069610   \n",
       "7181       1.0 -0.442139 -0.328404  0.031452  0.056017  0.424856  0.073288   \n",
       "7182       1.0 -0.616029 -0.302357  0.063417  0.095671  0.439930  0.069414   \n",
       "7183       1.0 -0.547168 -0.266780  0.056115  0.048947  0.423631  0.081924   \n",
       "7184       1.0 -0.520958 -0.258779 -0.070416 -0.025129  0.447967  0.180033   \n",
       "7185       1.0 -0.512794  0.056322  0.259677  0.030140  0.369783 -0.117154   \n",
       "7186       1.0 -0.591520 -0.268901  0.050042  0.116960  0.444706  0.059268   \n",
       "7187       1.0 -0.507564 -0.249969  0.031781 -0.079888  0.484274  0.125143   \n",
       "7188       1.0 -0.512599 -0.171956  0.325813  0.169600  0.421567 -0.123749   \n",
       "7189       1.0 -0.558546 -0.238442  0.066527  0.123090  0.395953  0.066522   \n",
       "7190       1.0 -0.554504 -0.337717  0.035533  0.034511  0.443451  0.093889   \n",
       "7191       1.0 -0.517273 -0.370574  0.030673  0.068097  0.402890  0.096628   \n",
       "7192       1.0 -0.582557 -0.343237  0.029468  0.064179  0.385596  0.114905   \n",
       "7193       1.0 -0.519497 -0.307553 -0.004922  0.072865  0.377131  0.086866   \n",
       "7194       1.0 -0.508833 -0.324106  0.062068  0.078211  0.397188  0.094596   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10       ...        MFCCs_14  MFCCs_15  \\\n",
       "0    -0.150063 -0.171128  0.124676       ...        0.082245  0.135752   \n",
       "1    -0.222475 -0.207693  0.170883       ...        0.022786  0.163320   \n",
       "2    -0.242234 -0.219153  0.232538       ...        0.050791  0.207338   \n",
       "3    -0.194347 -0.098181  0.270375       ...       -0.011567  0.100413   \n",
       "4    -0.265423 -0.172700  0.266434       ...        0.037439  0.219153   \n",
       "5    -0.213767 -0.127916  0.277353       ...        0.012486  0.180641   \n",
       "6    -0.252300 -0.167117  0.220027       ...        0.027070  0.216923   \n",
       "7    -0.183329 -0.158483  0.192567       ...       -0.009015  0.184266   \n",
       "8    -0.173730 -0.157857  0.207181       ...       -0.044984  0.064425   \n",
       "9    -0.294179 -0.223236  0.268435       ...        0.042678  0.236484   \n",
       "10   -0.216262 -0.189334  0.261960       ...        0.051362  0.221784   \n",
       "11   -0.191860 -0.133537  0.220020       ...       -0.025145  0.119870   \n",
       "12   -0.288733 -0.146731  0.314207       ...        0.016204  0.198509   \n",
       "13   -0.294064 -0.222278  0.282338       ...        0.039459  0.202870   \n",
       "14   -0.202826 -0.142236  0.235510       ...       -0.025456  0.099738   \n",
       "15   -0.314418 -0.252324  0.288897       ...        0.041608  0.236627   \n",
       "16   -0.155007 -0.137743  0.200262       ...       -0.012428  0.094166   \n",
       "17   -0.242952 -0.232617  0.235722       ...       -0.015118  0.151180   \n",
       "18   -0.207998 -0.219215  0.182845       ...       -0.037064  0.132052   \n",
       "19    0.016878 -0.171288 -0.115424       ...        0.150033 -0.030006   \n",
       "20   -0.169936 -0.121461  0.237437       ...        0.007265  0.163426   \n",
       "21   -0.192200 -0.187348  0.180486       ...       -0.092437  0.111833   \n",
       "22   -0.172111 -0.115698  0.251256       ...        0.049506  0.205311   \n",
       "23   -0.193793 -0.151462  0.212130       ...        0.008007  0.150663   \n",
       "24   -0.216492 -0.133865  0.278309       ...        0.060910  0.187107   \n",
       "25   -0.172653 -0.127641  0.190017       ...       -0.007142  0.124032   \n",
       "26   -0.197260 -0.124021  0.256757       ...        0.017556  0.174776   \n",
       "27   -0.146034 -0.127461  0.170725       ...       -0.100023  0.083705   \n",
       "28   -0.180608 -0.169064  0.221722       ...        0.041270  0.166617   \n",
       "29   -0.183926 -0.108442  0.245208       ...        0.008401  0.161657   \n",
       "...        ...       ...       ...       ...             ...       ...   \n",
       "7165  0.112706 -0.071058 -0.114414       ...       -0.010658 -0.025423   \n",
       "7166  0.120438  0.042605 -0.053960       ...        0.022934 -0.033569   \n",
       "7167  0.276750  0.232506 -0.372219       ...        0.138802 -0.128108   \n",
       "7168  0.078670 -0.243258 -0.120933       ...        0.244978  0.052956   \n",
       "7169  0.035056 -0.149125 -0.099348       ...        0.062459  0.022637   \n",
       "7170  0.125361 -0.023455 -0.064192       ...        0.055126  0.002086   \n",
       "7171  0.113272 -0.034906 -0.055563       ...        0.014452 -0.002528   \n",
       "7172  0.119675 -0.038130 -0.033289       ...        0.034721  0.030751   \n",
       "7173  0.109081 -0.049473 -0.044991       ...        0.017840  0.019535   \n",
       "7174  0.094837 -0.047792 -0.063015       ...        0.018963 -0.000422   \n",
       "7175 -0.197498  0.031180  0.096919       ...       -0.112334  0.006203   \n",
       "7176 -0.146350  0.040779  0.105841       ...       -0.075514  0.012561   \n",
       "7177 -0.136494  0.027486  0.106110       ...       -0.038105  0.029394   \n",
       "7178 -0.155093  0.035657  0.121933       ...       -0.049190  0.037494   \n",
       "7179 -0.133406  0.056485  0.093265       ...       -0.059179  0.029580   \n",
       "7180 -0.155217  0.080287  0.127136       ...       -0.072345  0.008949   \n",
       "7181 -0.140148  0.043070  0.087675       ...       -0.088273 -0.009950   \n",
       "7182 -0.145534  0.031354  0.069073       ...       -0.042672  0.051841   \n",
       "7183 -0.184252  0.024682  0.111803       ...       -0.057318  0.013367   \n",
       "7184 -0.062297  0.032410 -0.005379       ...       -0.095316  0.055439   \n",
       "7185 -0.189292  0.248948  0.193566       ...        0.127350  0.123271   \n",
       "7186 -0.158389  0.066648  0.083924       ...       -0.072221  0.022283   \n",
       "7187 -0.069555  0.114265  0.099647       ...       -0.058002  0.132482   \n",
       "7188 -0.298284  0.089382  0.243902       ...        0.008195  0.094519   \n",
       "7189 -0.152216  0.078294  0.094184       ...       -0.071421  0.054151   \n",
       "7190 -0.100753  0.037087  0.081075       ...       -0.059364  0.024206   \n",
       "7191 -0.116460  0.063727  0.089034       ...       -0.105600  0.030767   \n",
       "7192 -0.103317  0.070370  0.081317       ...       -0.078615  0.024861   \n",
       "7193 -0.115799  0.056979  0.089316       ...       -0.075320  0.022903   \n",
       "7194 -0.117672  0.058874  0.076180       ...       -0.073415  0.042517   \n",
       "\n",
       "      MFCCs_16  MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  MFCCs_21  MFCCs_22  \\\n",
       "0    -0.024017 -0.108351 -0.077623 -0.009568  0.057684  0.118680  0.014038   \n",
       "1     0.012022 -0.090974 -0.056510 -0.035303  0.020140  0.082263  0.029056   \n",
       "2     0.083536 -0.050691 -0.023590 -0.066722 -0.025083  0.099108  0.077162   \n",
       "3    -0.050224 -0.136009 -0.177037 -0.130498 -0.054766 -0.018691  0.023954   \n",
       "4     0.062837 -0.048885 -0.053074 -0.088550 -0.031346  0.108610  0.079244   \n",
       "5     0.055242 -0.080487 -0.130089 -0.171478 -0.071569  0.077643  0.064903   \n",
       "6     0.064853 -0.046620 -0.055146 -0.085972 -0.009127  0.065630  0.044040   \n",
       "7     0.075654 -0.055978 -0.048219 -0.056637 -0.022419  0.070085  0.021419   \n",
       "8    -0.032167 -0.120723 -0.112607 -0.156933 -0.118527 -0.002471  0.002304   \n",
       "9     0.053436 -0.051073 -0.052568 -0.111338 -0.040014  0.090204  0.088025   \n",
       "10    0.111884 -0.034082 -0.120716 -0.100800 -0.001992  0.111462  0.103637   \n",
       "11   -0.018260 -0.119167 -0.110900 -0.112485 -0.053184  0.044291 -0.011456   \n",
       "12    0.078510 -0.062939 -0.071182 -0.066827 -0.028048  0.058353  0.064368   \n",
       "13    0.029333 -0.071544 -0.060630 -0.067230 -0.038196  0.070127  0.048440   \n",
       "14   -0.015500 -0.138830 -0.139922 -0.126448 -0.067570  0.057888 -0.011998   \n",
       "15    0.071433 -0.058694 -0.072913 -0.064263  0.022455  0.130752  0.074132   \n",
       "16   -0.013232 -0.074168 -0.083995 -0.104413 -0.071431  0.028842  0.019180   \n",
       "17    0.029547 -0.051154 -0.038580 -0.022396 -0.018891  0.051480  0.031871   \n",
       "18   -0.000640 -0.110969 -0.105833 -0.115237 -0.012819  0.083194  0.052101   \n",
       "19   -0.231130 -0.253103 -0.154244 -0.002606  0.092999  0.091724  0.003595   \n",
       "20    0.047060 -0.045409 -0.067118 -0.047625 -0.005875  0.053107  0.030669   \n",
       "21   -0.047993 -0.163367 -0.170739 -0.169508 -0.112446  0.065072  0.050254   \n",
       "22    0.066123 -0.044077 -0.067219 -0.058514 -0.001358  0.082058  0.045492   \n",
       "23   -0.028506 -0.158932 -0.098565 -0.078413 -0.043410  0.033478 -0.006953   \n",
       "24    0.030893 -0.043595 -0.052536 -0.024106  0.016081  0.062506  0.042285   \n",
       "25   -0.039927 -0.105466 -0.070941 -0.085853 -0.025053  0.055194  0.003098   \n",
       "26    0.033374 -0.078277 -0.023172  0.002809  0.009133  0.063916  0.047634   \n",
       "27   -0.061133 -0.172904 -0.164822 -0.152341 -0.068851  0.024412 -0.009821   \n",
       "28    0.009967 -0.067536 -0.084953 -0.116397 -0.008499  0.101151  0.022322   \n",
       "29    0.025020 -0.072937 -0.018316 -0.034315 -0.029563  0.051715  0.023925   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7165 -0.009011 -0.006677 -0.070338  0.003964  0.032534  0.002975  0.002724   \n",
       "7166 -0.024850  0.007785 -0.002231  0.020593  0.014499  0.008208  0.018023   \n",
       "7167 -0.250080  0.029924  0.031286 -0.038367 -0.007837  0.102445  0.000755   \n",
       "7168 -0.204797  0.090483  0.126233  0.015162  0.059531  0.050905 -0.026956   \n",
       "7169  0.007059 -0.041610 -0.039468  0.086045  0.071944 -0.021574  0.036031   \n",
       "7170 -0.014339  0.004518 -0.013307 -0.001609  0.022170  0.014327  0.003001   \n",
       "7171 -0.010471 -0.005648 -0.028727  0.031281  0.033687  0.005242  0.014982   \n",
       "7172  0.002621 -0.027436 -0.007999  0.058854  0.008365  0.019086  0.090131   \n",
       "7173  0.002808 -0.008959 -0.034239  0.036489  0.042205  0.003017  0.005602   \n",
       "7174  0.015442  0.021719 -0.041396 -0.013619  0.010337  0.017903  0.022108   \n",
       "7175 -0.033484  0.052054  0.114138  0.069353  0.050519 -0.069281 -0.106642   \n",
       "7176 -0.001182  0.062850  0.038051  0.019184  0.027745 -0.109677 -0.131287   \n",
       "7177 -0.022552  0.049024  0.109761  0.043604  0.047369 -0.018168 -0.085380   \n",
       "7178 -0.028617  0.048454  0.072420  0.017823 -0.021418 -0.094280 -0.091600   \n",
       "7179  0.030742  0.079075  0.125759  0.044132  0.017652 -0.077831 -0.132563   \n",
       "7180 -0.041878  0.053063  0.085869  0.020705  0.009959 -0.072003 -0.121693   \n",
       "7181 -0.034092  0.024943  0.068279  0.015953  0.058530 -0.009746 -0.080940   \n",
       "7182  0.023079  0.056971  0.037285  0.023818  0.042104 -0.035603 -0.097343   \n",
       "7183 -0.022609  0.049831  0.115522  0.051333  0.019697 -0.061764 -0.078648   \n",
       "7184  0.056085  0.027392  0.019266 -0.057772  0.037710  0.047717  0.001436   \n",
       "7185 -0.088578  0.096589  0.255261  0.047039 -0.016643 -0.046598 -0.055862   \n",
       "7186 -0.012293  0.074444  0.117996  0.045522  0.050734 -0.034757 -0.085131   \n",
       "7187 -0.016865  0.011524  0.111998  0.015886  0.008636 -0.021933 -0.069692   \n",
       "7188 -0.007756  0.021225  0.157321  0.042847  0.006852  0.005439 -0.013693   \n",
       "7189  0.015341  0.034202  0.040540 -0.003755  0.036059 -0.031853 -0.090206   \n",
       "7190 -0.000861  0.069430  0.071001  0.021591  0.052449 -0.021860 -0.079860   \n",
       "7191  0.006457  0.061127  0.068978  0.017745  0.046461 -0.015418 -0.101892   \n",
       "7192  0.008696  0.082474  0.077771 -0.009688  0.027834 -0.000531 -0.080425   \n",
       "7193  0.001924  0.051796  0.069073  0.017963  0.041803 -0.027911 -0.096895   \n",
       "7194  0.004158  0.061455  0.072983 -0.003980  0.031560 -0.029355 -0.087910   \n",
       "\n",
       "             Species  \n",
       "0     AdenomeraAndre  \n",
       "1     AdenomeraAndre  \n",
       "2     AdenomeraAndre  \n",
       "3     AdenomeraAndre  \n",
       "4     AdenomeraAndre  \n",
       "5     AdenomeraAndre  \n",
       "6     AdenomeraAndre  \n",
       "7     AdenomeraAndre  \n",
       "8     AdenomeraAndre  \n",
       "9     AdenomeraAndre  \n",
       "10    AdenomeraAndre  \n",
       "11    AdenomeraAndre  \n",
       "12    AdenomeraAndre  \n",
       "13    AdenomeraAndre  \n",
       "14    AdenomeraAndre  \n",
       "15    AdenomeraAndre  \n",
       "16    AdenomeraAndre  \n",
       "17    AdenomeraAndre  \n",
       "18    AdenomeraAndre  \n",
       "19    AdenomeraAndre  \n",
       "20    AdenomeraAndre  \n",
       "21    AdenomeraAndre  \n",
       "22    AdenomeraAndre  \n",
       "23    AdenomeraAndre  \n",
       "24    AdenomeraAndre  \n",
       "25    AdenomeraAndre  \n",
       "26    AdenomeraAndre  \n",
       "27    AdenomeraAndre  \n",
       "28    AdenomeraAndre  \n",
       "29    AdenomeraAndre  \n",
       "...              ...  \n",
       "7165     ScinaxRuber  \n",
       "7166     ScinaxRuber  \n",
       "7167     ScinaxRuber  \n",
       "7168     ScinaxRuber  \n",
       "7169     ScinaxRuber  \n",
       "7170     ScinaxRuber  \n",
       "7171     ScinaxRuber  \n",
       "7172     ScinaxRuber  \n",
       "7173     ScinaxRuber  \n",
       "7174     ScinaxRuber  \n",
       "7175     ScinaxRuber  \n",
       "7176     ScinaxRuber  \n",
       "7177     ScinaxRuber  \n",
       "7178     ScinaxRuber  \n",
       "7179     ScinaxRuber  \n",
       "7180     ScinaxRuber  \n",
       "7181     ScinaxRuber  \n",
       "7182     ScinaxRuber  \n",
       "7183     ScinaxRuber  \n",
       "7184     ScinaxRuber  \n",
       "7185     ScinaxRuber  \n",
       "7186     ScinaxRuber  \n",
       "7187     ScinaxRuber  \n",
       "7188     ScinaxRuber  \n",
       "7189     ScinaxRuber  \n",
       "7190     ScinaxRuber  \n",
       "7191     ScinaxRuber  \n",
       "7192     ScinaxRuber  \n",
       "7193     ScinaxRuber  \n",
       "7194     ScinaxRuber  \n",
       "\n",
       "[7195 rows x 23 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Frogs_MFCCs.csv')\n",
    "exclude = ['Family', 'Genus', 'RecordID']\n",
    "for excluded in exclude:\n",
    "    df.drop(excluded, axis=1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['AdenomeraAndre'],\n",
       "       ['AdenomeraAndre'],\n",
       "       ['AdenomeraAndre'],\n",
       "       ..., \n",
       "       ['ScinaxRuber'],\n",
       "       ['ScinaxRuber'],\n",
       "       ['ScinaxRuber']], dtype=object)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(Tanuran,(Tanuran.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(Tanuran))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.53e-01,  -1.06e-01,   2.01e-01, ...,   5.77e-02,   1.19e-01,\n",
       "          1.40e-02],\n",
       "       [  1.72e-01,  -9.90e-02,   2.68e-01, ...,   2.01e-02,   8.23e-02,\n",
       "          2.91e-02],\n",
       "       [  1.52e-01,  -8.30e-02,   2.87e-01, ...,  -2.51e-02,   9.91e-02,\n",
       "          7.72e-02],\n",
       "       ..., \n",
       "       [ -5.83e-01,  -3.43e-01,   2.95e-02, ...,   2.78e-02,  -5.31e-04,\n",
       "         -8.04e-02],\n",
       "       [ -5.19e-01,  -3.08e-01,  -4.92e-03, ...,   4.18e-02,  -2.79e-02,\n",
       "         -9.69e-02],\n",
       "       [ -5.09e-01,  -3.24e-01,   6.21e-02, ...,   3.16e-02,  -2.94e-02,\n",
       "         -8.79e-02]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = list(df.axes[1])\n",
    "data = df.as_matrix()\n",
    "classes = np.unique(data[:,-1]).tolist()\n",
    "classes.index(\"HylaMinuta\")\n",
    "Xanuran = data[:,:-1].astype(float)\n",
    "Tanuran = data[:,-1].tolist()\n",
    "\n",
    "for i, c in enumerate(Tanuran):\n",
    "    Tanuran[i] = classes.index(c)\n",
    "Tanuran = np.array(Tanuran)\n",
    "Tanuran = np.reshape(Tanuran,(-1,1))\n",
    "Xnames = names[:-1]\n",
    "Tnames = names[-1:]\n",
    "\n",
    "Xanuran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ..., \n",
       "       [9],\n",
       "       [9],\n",
       "       [9]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tanuran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7195, 21), (7195, 1))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xanuran.shape, Tanuran.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15, -0.11,  0.2 ,  0.32,  0.26,  0.1 , -0.15, -0.17,  0.12,\n",
       "         0.19, -0.08, -0.16,  0.08,  0.14, -0.02, -0.11, -0.08, -0.01,\n",
       "         0.06,  0.12,  0.01],\n",
       "       [ 0.17, -0.1 ,  0.27,  0.34,  0.27,  0.06, -0.22, -0.21,  0.17,\n",
       "         0.27, -0.1 , -0.25,  0.02,  0.16,  0.01, -0.09, -0.06, -0.04,\n",
       "         0.02,  0.08,  0.03]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xanuran[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tanuran[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672 samples in class 0\n",
      "3478 samples in class 1\n",
      "542 samples in class 2\n",
      "310 samples in class 3\n",
      "472 samples in class 4\n",
      "1121 samples in class 5\n",
      "270 samples in class 6\n",
      "114 samples in class 7\n",
      "68 samples in class 8\n",
      "148 samples in class 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('{} samples in class {}'.format(np.sum(Tanuran==i), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainNNs(Xanuran, Tanuran, 0.8, [0, 5, [5, 5]], 5, 100, classify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0.030507296733842958, 0.035441278665740115, 3.209761142730713],\n",
       " [5, 0.035024322446143175, 0.044753300903405166, 7.202175140380859],\n",
       " [[5, 5], 0.043571924947880494, 0.054482279360667116, 8.477503061294556]]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0.030507296733842958, 0.035441278665740115, 3.209761142730713]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestNetwork(summarize(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do an investigation like you did for the regression data. \n",
    "\n",
    "Test at least 10 different hidden layer structures. Then train another network with your best hidden layer structure on 0.8 of the data and use the trained network on the testing data (the remaining 0.2 of the date). \n",
    "\n",
    "Plot the predicted and actual `Species` for the testing data as an integer.  Discuss what you see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "Download [A6grader.tar](http://www.cs.colostate.edu/~anderson/cs440/notebooks/A6grader.tar) and extract `A6grader.py` from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing summarize([[[1,1], [1.2, 1.3, 1.4], [2.2, 2.3, 2.4], 0.5], [[2,2,2], [4.4, 4.3, 4.2], [6.5, 6.4, 6.3], 0.6]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[[1, 1], 1.3, 2.3000000000000003, 0.5], [[2, 2, 2], 4.3, 6.3999999999999995, 0.6]]\n",
      "\n",
      "Testing bestNetwork([[[1, 1], 1.3, 2.3, 0.5], [[2, 2, 2], 4.3, 1.3, 0.6]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[2, 2, 2], 4.3, 1.3, 0.6]\n",
      "\n",
      "X = np.random.uniform(-1, 1, (100, 3))\n",
      "T = np.hstack(((X**2 - 0.2*X**3).sum(axis=1,keepdims=True),\n",
      "               (np.sin(X)).sum(axis=1,keepdims=True)))\n",
      "result = trainNNs(X, T, 0.7, [0, 5, 10, [20, 20]], 10, 100, False)\n",
      "\n",
      "--- 20/20 points. Correct.\n",
      "\n",
      "Testing bestNetwork(summarize(result))\n",
      "\n",
      "--- 20/20 points. You correctly found that network [20, 20] is best.\n",
      "\n",
      "A6 Execution Grade is 60/60\n",
      "\n",
      "======================= The regression data set =======================\n",
      "\n",
      "--- _/5 points. Read the data in energydata_complete.csv into variables Xenergy and Tenergy.\n",
      "\n",
      "--- _/5 points. Train some networks by calling the NeuralNetwork constructor and train method and plot the error trace to help you decide now many iterations might be needed.\n",
      "\n",
      "--- _/5 points. Try at least 10 different hidden layer structures using trainNNs.\n",
      "\n",
      "--- _/5 points. Train another network with your best hidden layer structure on 0.8 of the data and test it on remaining 0.2 of the data. Plot the predicted and actual Appliances energy use, and the predicted and actual lights energy use, in two separate plots. Discuss what you see.\n",
      "\n",
      "======================= Classification data set =======================\n",
      "\n",
      "--- _/5 points. Read the data in Frogs_MFCCs.csv into variables Xanuran and Tanuran.\n",
      "\n",
      "--- _/5 points. Train some networks by calling the NeuralNetwork constructor and train method and plot the error trace to help you decide now many iterations might be needed.\n",
      "\n",
      "--- _/5 points. Try at least 10 different hidden layer structures using trainNNs.\n",
      "\n",
      "--- _/5 points. Train another network with your best hidden layer structure on 0.8 of the data and test it on remaining 0.2 of the data. Plot the predicted and actual Appliances energy use, and the predicted and actual lights energy use, in two separate plots. Discuss what you see.\n",
      "\n",
      "A6 Notebook Grade is __/40\n",
      "\n",
      "A6 FINAL GRADE is __/100\n"
     ]
    }
   ],
   "source": [
    "%run -i \"A6grader.py\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
